# Generaci贸n de Res煤menes de Documentos Judiciales con LLMs

Este repositorio contiene el c贸digo y los datos utilizados en el desarrollo de un pipeline basado en Modelos de Lenguaje de Gran Escala (LLMs) para la generaci贸n autom谩tica de res煤menes de documentos judiciales. 

##  Estructura del Repositorio

- **`pipeline2.py`**  
  Implementaci贸n del segundo dise帽o del pipeline, que sigue estos pasos:
  1. Carga un documento judicial completo. (Ya sea escogiendo el archivo de forma aleatoria o recibiendo el path de un archivo como input)
  2. Selecciona un conjunto de prompts predefinidos, uno para cada secci贸n del resumen (Datos de la causa, S铆ntesis y Sumarios).
  3. Procesa cada secci贸n del documento de manera independiente con su respectivo prompt, generando res煤menes individuales usando la API de Claude.
  4. **Evaluaci贸n autom谩tica con Claude**: Se utiliza Claude como evaluador para comparar el resumen generado con el original, evaluando coherencia, precisi贸n, relevancia, concisi贸n y fidelidad.

- **`resultados/`**  
  Carpeta con los res煤menes generados utilizando diferentes estrategias y modelos:
  - LLaMA y Claude como generadores.
  - M茅todos Zero-shot, One-shot y Few-shot.

- **`base/`**  
  Contiene los documentos judiciales en texto plano junto con sus res煤menes originales.

- **`analisis/`**  
  - Archivos de texto con los documentos utilizados en entrenamiento, validaci贸n y prueba.
  - Resultados de la clusterizaci贸n de documentos judiciales.

- **`prompts.text`**  
  Archivo con los prompts utilizados en cada estrategia de generaci贸n (`zero-shot`, `one-shot` y `few-shot`).  
  - La estrategia a usar se define con la variable `PROMPT_STRATEGY` (`"zero-shot"`, `"one-shot"` o `"few-shot"`).
  - Dependiendo de la estrategia seleccionada, se deben modificar:
    - El par谩metro `prompt_strategy` en el archivo `pipeline2.py`, este dato es 煤til para el json de los resultados.
    - Los valores de `prompt_datos`, `prompt_sintesis` y `prompt_sumarios` en `pipeline2.py`.

---

##  Instalaci贸n

###  Requisitos Previos
- Python 3.8+
- API Key de **Claude** (Anthropic)

###  Instalaci贸n de Dependencias

Primero, instala las librer铆as necesarias ejecutando:

```bash
pip install -r requirements.txt 
```

El pipeline requiere una API Key de Claude para la evaluaci贸n autom谩tica. Debes almacenarla en una variable de entorno llamada LLM_API_KEY:

```bash
export LLM_API_KEY="TU_CLAVE_AQUI"
```

(O agr茅gala en tu configuraci贸n de entorno si usas Windows o un entorno virtual.)

---

## 锔 Uso

Puedes ejecutar el pipeline con un archivo espec铆fico o dejar que seleccione uno aleatorio:

```bash
python3 pipeline2.py <ruta_al_documento>
```

Si no se proporciona una ruta, el script elegir谩 un documento judicial aleatoriamente de la carpeta `base/`.